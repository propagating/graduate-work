{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "7ef0d9ec",
   "metadata": {},
   "source": [
    "# Assignment1: Classification of Sonar dataset With one Hidden Layer\n",
    "\n",
    "In this assignment, you will implement a neural network with one hidden layer from scratch using numpy operations to classify the UCI sonar dataset to Rock or Mine: https://www.kaggle.com/datasets/shrutimehta/nasa-asteroids-classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b161a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b54a0b",
   "metadata": {},
   "source": [
    "## Load  and Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342464d6",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe and show the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cbeb943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       0       1       2       3       4       5       6       7       8   \\\n0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n\n       9   ...      51      52      53      54      55      56      57  \\\n0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n\n       58      59  60  \n0  0.0090  0.0032   R  \n1  0.0052  0.0044   R  \n2  0.0095  0.0078   R  \n3  0.0040  0.0117   R  \n4  0.0107  0.0094   R  \n\n[5 rows x 61 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0200</td>\n      <td>0.0371</td>\n      <td>0.0428</td>\n      <td>0.0207</td>\n      <td>0.0954</td>\n      <td>0.0986</td>\n      <td>0.1539</td>\n      <td>0.1601</td>\n      <td>0.3109</td>\n      <td>0.2111</td>\n      <td>...</td>\n      <td>0.0027</td>\n      <td>0.0065</td>\n      <td>0.0159</td>\n      <td>0.0072</td>\n      <td>0.0167</td>\n      <td>0.0180</td>\n      <td>0.0084</td>\n      <td>0.0090</td>\n      <td>0.0032</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0453</td>\n      <td>0.0523</td>\n      <td>0.0843</td>\n      <td>0.0689</td>\n      <td>0.1183</td>\n      <td>0.2583</td>\n      <td>0.2156</td>\n      <td>0.3481</td>\n      <td>0.3337</td>\n      <td>0.2872</td>\n      <td>...</td>\n      <td>0.0084</td>\n      <td>0.0089</td>\n      <td>0.0048</td>\n      <td>0.0094</td>\n      <td>0.0191</td>\n      <td>0.0140</td>\n      <td>0.0049</td>\n      <td>0.0052</td>\n      <td>0.0044</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0262</td>\n      <td>0.0582</td>\n      <td>0.1099</td>\n      <td>0.1083</td>\n      <td>0.0974</td>\n      <td>0.2280</td>\n      <td>0.2431</td>\n      <td>0.3771</td>\n      <td>0.5598</td>\n      <td>0.6194</td>\n      <td>...</td>\n      <td>0.0232</td>\n      <td>0.0166</td>\n      <td>0.0095</td>\n      <td>0.0180</td>\n      <td>0.0244</td>\n      <td>0.0316</td>\n      <td>0.0164</td>\n      <td>0.0095</td>\n      <td>0.0078</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0100</td>\n      <td>0.0171</td>\n      <td>0.0623</td>\n      <td>0.0205</td>\n      <td>0.0205</td>\n      <td>0.0368</td>\n      <td>0.1098</td>\n      <td>0.1276</td>\n      <td>0.0598</td>\n      <td>0.1264</td>\n      <td>...</td>\n      <td>0.0121</td>\n      <td>0.0036</td>\n      <td>0.0150</td>\n      <td>0.0085</td>\n      <td>0.0073</td>\n      <td>0.0050</td>\n      <td>0.0044</td>\n      <td>0.0040</td>\n      <td>0.0117</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0762</td>\n      <td>0.0666</td>\n      <td>0.0481</td>\n      <td>0.0394</td>\n      <td>0.0590</td>\n      <td>0.0649</td>\n      <td>0.1209</td>\n      <td>0.2467</td>\n      <td>0.3564</td>\n      <td>0.4459</td>\n      <td>...</td>\n      <td>0.0031</td>\n      <td>0.0054</td>\n      <td>0.0105</td>\n      <td>0.0110</td>\n      <td>0.0015</td>\n      <td>0.0072</td>\n      <td>0.0048</td>\n      <td>0.0107</td>\n      <td>0.0094</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 61 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_dataframe = pd.read_csv(\"data/sonar.all-data.csv\", header=None)\n",
    "sonar_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a57c1",
   "metadata": {},
   "source": [
    "How many rows and columns does this data set have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d424adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208  rows\n",
      "61  columns\n"
     ]
    }
   ],
   "source": [
    "print(sonar_dataframe.shape[0], ' rows')\n",
    "print(sonar_dataframe.shape[1], ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720805e",
   "metadata": {},
   "source": [
    "Check the columns of the dataframe using info() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "687cbbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method DataFrame.info of          0       1       2       3       4       5       6       7       8   \\\n0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n\n         9   ...      51      52      53      54      55      56      57  \\\n0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n\n         58      59  60  \n0    0.0090  0.0032   R  \n1    0.0052  0.0044   R  \n2    0.0095  0.0078   R  \n3    0.0040  0.0117   R  \n4    0.0107  0.0094   R  \n..      ...     ...  ..  \n203  0.0193  0.0157   M  \n204  0.0062  0.0067   M  \n205  0.0077  0.0031   M  \n206  0.0036  0.0048   M  \n207  0.0061  0.0115   M  \n\n[208 rows x 61 columns]>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_dataframe.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc49990",
   "metadata": {},
   "source": [
    "Convert the target column to 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af88cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_dataframe[60]=sonar_dataframe[60].map({'R': 0,'M' :1 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ec31f",
   "metadata": {},
   "source": [
    "Convert the sonar_dataframe to numpy array using the values function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba952ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_np_array = np.array(sonar_dataframe.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115c225",
   "metadata": {},
   "source": [
    "Split the dataset into  80\\% train and 20\\% validation usig the train_test_split command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fbb3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sonar_np_array, test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc748d1",
   "metadata": {},
   "source": [
    "split the last column as the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b83058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:,0:60].astype(float)\n",
    "Y_train = train[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e96a9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[:,0:60].astype(float)\n",
    "Y_test = test[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141bc5b",
   "metadata": {},
   "source": [
    "## Train a logistic Regression Model\n",
    "Use sklearn to train a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66dd7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n       0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n       0., 1., 1., 0., 1., 1., 0., 1.])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, Y_train)\n",
    "logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda66b7f",
   "metadata": {},
   "source": [
    "What is the accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8a305d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "score = logit.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425349b",
   "metadata": {},
   "source": [
    "## Building a Neural Network Model\n",
    "In this section, you will create an NN model with one hidden layer and a sigmoid function for the output layer. Use a tanh functiomn for the hidden layer activation. Use average cross entropy for the loss function.\n",
    "Fill in the missing code wherever you see \\#CODE HERE comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f0df930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(2) \n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x) * 0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h) * 0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6af4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58bda184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    Z1 = np.dot(W1,X.T) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b1bf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Y_hat, Y, parameters):\n",
    "    m = Y.shape[1] # number of example\n",
    "    logprobs = logprobs = np.multiply(Y ,np.log(Y_hat)) + np.multiply((1-Y), np.log(1-Y_hat))\n",
    "    cost = (-1/m) * np.sum(logprobs)\n",
    "    cost = float(np.squeeze(cost)) \n",
    "                                    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d30ec058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[0]\n",
    "   \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    Z1 = cache[\"Z1\"]\n",
    "    Z2 = cache[\"Z2\"]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fedc4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    " \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2863d",
   "metadata": {},
   "source": [
    "Below is the main function which puts all the previous functions together to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e98f6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(X, Y, num_of_hidden_units, learning_rate, num_iterations = 10000, print_cost=False):\n",
    "    \n",
    "    input_size=X_train.shape[1] \n",
    "    num_of_output_units=1\n",
    "    parameters = initialize_parameters(input_size, num_of_hidden_units, num_of_output_units)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # gradient descent Loop\n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if print_cost and i % 10000 == 0:\n",
    "            cost = cross_entropy(A2, Y, parameters)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c22ba",
   "metadata": {},
   "source": [
    "Predict is the scoring function to get predictions for new instances using the trained model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cb513d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = (A2 > 0.5)    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81ba4b",
   "metadata": {},
   "source": [
    "Train the model using the train_nn_model defined above with 5 units in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99e257b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = train_nn_model(X_train, Y_train, 5, 0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a861a6b",
   "metadata": {},
   "source": [
    "Use the predict function to generate the output for the X_test data. What is the accuracy of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3000ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predict(parameters, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "010999ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: %d' % float((np.dot(Y_test,predictions.T) + np.dot(1-Y_test,1-predictions.T))/float(Y_test.size)*100) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b46d2a",
   "metadata": {},
   "source": [
    "## Tunning the Size of Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd5a48",
   "metadata": {},
   "source": [
    "Run the following code to see which size for the hodden layer gives you the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f6789dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 hidden units: 71.42857142857143 %\n",
      "Accuracy for 2 hidden units: 69.04761904761905 %\n",
      "Accuracy for 3 hidden units: 73.80952380952381 %\n",
      "Accuracy for 4 hidden units: 76.19047619047619 %\n",
      "Accuracy for 5 hidden units: 66.66666666666666 %\n",
      "Accuracy for 10 hidden units: 64.28571428571429 %\n",
      "Accuracy for 20 hidden units: 69.04761904761905 %\n",
      "Accuracy for 30 hidden units: 71.42857142857143 %\n",
      "Accuracy for 50 hidden units: 73.80952380952381 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x3200 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "hidden_layer_sizes = [1, 2, 3, 4, 5, 10, 20, 30,50]\n",
    "for i, num_hidden_units in enumerate(hidden_layer_sizes):\n",
    "    parameters = train_nn_model(X_train, np.expand_dims(Y_train,axis=0),num_hidden_units ,0.01, num_iterations = 100000)\n",
    "    predictions = predict(parameters, X_test)\n",
    "    accuracy = float((np.dot(Y_test,predictions.T) + np.dot(1-Y_test,1-predictions.T))/float(Y_test.size)*100)\n",
    "    print (\"Accuracy for {} hidden units: {} %\".format(num_hidden_units, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af352a",
   "metadata": {},
   "source": [
    "Which one was the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592b025",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best model was back propagation with 4 hidden layers based on the accuracy scores we got.Above 4 hidden layers we start to see the model becoming over fit."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
